{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Contextual bandits (Bayesian Linear Regression in Thompson Sampling)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "5HF_jfalFMuk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Author: Weiwen Leung\n",
        "\n",
        "Date created: October 2018\n",
        "\n",
        "Purpose: To create a contextual multi-armed bandit that uses Bayesian Linear Regression and Thompson Sampling.\n",
        "\n",
        "Acknowledgements: Linear Regression equations taken from Bishop (2006)\n",
        "\n",
        "# What is a Contextual Bandit?\n",
        "\n",
        "A multi-armed bandit is an algorithm that self-learns the optimal treatment to achieve an outcome.\n",
        "\n",
        "A **contextual** multi-armed bandit is an algorithm that self-learns the optimal **personalized** treatment to achieve an outcome. (In other words, a contextual bandit is a generalization of the multi-armed bandit)\n",
        "\n",
        "Consider the case of encouraging people to donate to charity. Imagine you want to encourage people to donate to charity, and you have five different messages to encourage charitable giving, but are not sure which works best. A multi-armed bandit would generally initially randomly test explanations. However, as users see the explanations and make their donation decisions, more effective messages are more likely to be shown more frequently. For example, suppose that upon seeing a certain message, a user makes a large donation. That message will be slightly more likely to be shown to the next user.\n",
        "\n",
        "A **contextual** multi-armed bandit does everything that a multi-armed bandit does, but also takes into account user characteristics (e.g. age, gender, location). For example, the donations of male users impact the probability of messages that will be displayed to male users more than the probability of messages that will be displayed to female users. This can be very useful for providing personalized treatments; e.g. males may be more motivated to donate if the donation appeal contains a photo of a female, while females may be more motivated to donate if the donation appeal contains a photo of a male.\n",
        "\n",
        "# Structure of this notebook\n",
        "\n",
        "There are two classes: \n",
        "\n",
        "1. BayesLinear: creates Bayesian Linear Regression objects that allow for personalized treatments\n",
        "\n",
        "2. Experiment: runs experiments that use Bayesian Linear Regressions to provide personalized treatments\n",
        "\n",
        "To create a contextual bandit, first create a BayesLinear object (specifying the priors) \n",
        "\n",
        "Then create an Experiment object (specify the number of covariates, the number of experimental variables, a BayesLinear object, the data source, and the data generating process).\n",
        "\n",
        "\n",
        "# \"Experiment\" Flow\n",
        "\n",
        "      1. load observation (participant characteristics)\n",
        "      2. conduct Thompson Sampling (take a random sample from distribution of coefficients)\n",
        "      3. calculate which treatments to include (i.e. which treatments increase donations, if donations is the dependent variable)\n",
        "      4. give treatments, observe reward (reward calculated from data generating process)\n",
        "      5. calculate posterior by Bayesian updating.\n",
        "      6. when next observation comes, posterior becomes new prior.\n",
        "      \n",
        "# Mechanics of Bayesian Linear Regression\n",
        "\n",
        "## Notation:\n",
        "$t$: target (statisticians call this the \"dependent variable\")\n",
        "\n",
        "$\\vec{w}$: weight vector (\"regression coefficients\")\n",
        "\n",
        "$\\vec{x}$: raw feature vector (\"raw data\")\n",
        "\n",
        "$\\phi$: transformed feature vector (\"data\")\n",
        "\n",
        "$\\beta$: precision of noise \n",
        "\n",
        " $\\epsilon$: error term/residual\n",
        " \n",
        "$\\vec{m}_0, \\vec{m}_N$: prior of mean of weight vector after $0$ and $N$ observations respectively.\n",
        "\n",
        "$\\vec{S}_0, \\vec{S}_N$: prior of covariance of weight vector after $0$ and $N$ observations respectively.\n",
        "\n",
        "## The Target\n",
        "$$t = f(\\vec{x}, \\vec{w}) + \\epsilon $$\n",
        "\n",
        "\n",
        "### The Model\n",
        "\n",
        "$$p(t \\mid \\vec{x}, \\vec{w}) =  Norm(t \\mid y(\\vec{x}, \\vec{w}), \\beta^{-1}) = Norm(t \\mid \\vec{w}^T \\vec{\\phi}(\\vec{x}), \\beta^{-1}) $$ \n",
        "\n",
        "hope: to find values for $\\vec{w}$ that make a good fit to the true model, given by \n",
        "\n",
        "\n",
        "### Theory\n",
        "\n",
        "$$p(\\vec{w}) = Norm(\\vec{w} \\mid \\vec{m}_0, \\vec{S}_0) $$\n",
        "\n",
        "\n",
        "where the parameters are updated via these equations:\n",
        "$$ \\vec{S}^{-1}_N = \\vec{S}_0^{-1} + \\beta\\vec{\\Phi}^T\\vec{\\Phi} $$\n",
        "$$ \\vec{m}_N = \\vec{S}_N(\\vec{S}_0^{-1}\\vec{m}_0 + \\beta\\vec{\\Phi}^T\\vec{t}) $$\n",
        "\n",
        "Note that if data comes in sequentially, the posterior of the previous step becomes the prior of the current step and we only need to calculate the updates to $\\vec{m}_N$ and $\\vec{S}_N^{-1}$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nmdXIVGNFMul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.random import normal, uniform\n",
        "from scipy.stats import multivariate_normal as mv_norm\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dEKY3cFZFMuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LinearBayes(object):\n",
        "    \"\"\"\n",
        "    A class that holds parameter prior/posterior and handles \n",
        "    the hyper-parameter updates with new data\n",
        "    \n",
        "    Note:  variables starting with \"v_\" indicate Nx1 dimensional \n",
        "        column vectors, those starting with \"m_\" indicate \n",
        "        matrices, and those starting with \"a_\" indicate \n",
        "        1xN dimensional arrays.\n",
        "    \n",
        "    Args:\n",
        "        a_m0 (np.array): prior mean vector of size 1xM\n",
        "        m_S0 (np.ndarray): prior covariance matrix of size MxM\n",
        "        beta (float): known real-data noise precision\n",
        "        \n",
        "    \"\"\"\n",
        "    def __init__(self, a_m0, m_S0, beta):\n",
        "        self.prior = mv_norm(mean=a_m0, cov=m_S0)\n",
        "        self.v_m0 = a_m0.reshape(a_m0.shape + (1,)) #reshape to column vector\n",
        "        self.m_S0 = m_S0\n",
        "        self.beta = beta\n",
        "        \n",
        "        self.v_mN = self.v_m0\n",
        "        self.m_SN = self.m_S0\n",
        "        self.posterior = self.prior\n",
        "           \n",
        "    def get_phi(self, a_x):\n",
        "        \"\"\"\n",
        "        Returns the design matrix of size (NxM) for a feature vector v_x.\n",
        "        In this case, this function merely adds the phi_0 dummy basis\n",
        "        that's equal to 1 for all elements.\n",
        "        \n",
        "        Args:\n",
        "            a_x (np.array): input features of size 1xN\n",
        "        \"\"\"\n",
        "        if len(a_x.shape) > 1: # if there is more than one observation per batch\n",
        "          m_phi = np.ones(a_x.shape[0], a_x.shape[1] + 1)\n",
        "          m_phi[:, 1:a_x.shape[1]] = a_x\n",
        "        else: # if there is exactly one observation per batch\n",
        "          #m_phi = np.append([1], a_x) # no need to append [1]. Weiwen commented because it seems that you are adding a constant twice\n",
        "          m_phi = a_x\n",
        "          m_phi = np.array([m_phi])\n",
        "\n",
        "        \n",
        "        return m_phi\n",
        "        \n",
        "    def set_posterior(self, a_x, a_t):\n",
        "        \"\"\"\n",
        "        Updates mN and SN given vectors of x-values and t-values\n",
        "        \"\"\"\n",
        "        # Need to convert v_t from an array into a column vector\n",
        "        # to correctly compute matrix multiplication\n",
        "        v_t = a_t.reshape(a_t.shape + (1,))\n",
        "\n",
        "        m_phi = self.get_phi(a_x)\n",
        "        self.m_SN = np.linalg.inv(np.linalg.inv(self.m_S0) + self.beta*m_phi.T.dot(m_phi))\n",
        "        if len(v_t.shape) == 1:\n",
        "          v_t = np.array([v_t]) # casts a 1D array as a 2D in order to avoid adding (M, 1) array to an (M,) array and getting (M by M)\n",
        "        self.v_mN = self.m_SN.dot(np.linalg.inv(self.m_S0).dot(self.v_m0) + \\\n",
        "                                      self.beta*m_phi.T.dot(v_t))\n",
        "        \n",
        "        self.posterior = mv_norm(mean=self.v_mN.flatten(), cov=self.m_SN)\n",
        "\n",
        "    \n",
        "    def thompson_sampling(self):\n",
        "      \"\"\"\n",
        "      Performs Thompson Sampling on the prior distributions of regression coefficients.\n",
        "      \"\"\"      \n",
        "      return np.random.multivariate_normal(self.v_m0.flatten(), self.m_S0) # note np multivariate_normal draws a sample, while scipy's multivariate normal is the random variable itself\n",
        "    \n",
        "    \n",
        "    def replace_prior(self):\n",
        "      \"\"\"\n",
        "      After the posterior has been updated, the current prior becomes the posterior for the next data point(s)\n",
        "      \"\"\"\n",
        "      self.prior = self.posterior\n",
        "      self.v_m0 = self.prior.mean.reshape(self.prior.mean.shape + (1,)) #reshape to column vector\n",
        "      self.m_S0 = self.prior.cov\n",
        "      \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3kqAWxKViQ7O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After you create a BayesLinear object, create an Experiment object that takes as input:\n",
        "\n",
        "* number of covariates\n",
        "* number of experimental variables\n",
        "*   BayesLinear object\n",
        "*   data set (created through the user-specified data generating process; in future, will allow CSV)\n",
        "* regression coefficients for data generating process\n",
        "\n",
        "By convention, order of regression coefficients is as follows:\n",
        "\n",
        "$[constant, covar1, covar2, ..., covarM, constant*exptvar1, covar1*exptvar1, ..., covarM*exptvar1, constant*exptvar2, covar1*exptvar2, ..., constant*exptvar3, ...]$\n",
        "\n",
        "\n",
        "For example, with one covariate and two experimental treatments, we have:\n",
        "\n",
        "$[constant, covar1, exptvar1, exptvar1*covar1, exptvar2, exptvar2*covar1]$\n",
        "\n",
        "i.e. regression equation can be written as $y = \\beta_0 + \\beta_1*cov1 + \\beta_2*expt1 + \\beta_3*expt1*cov1 + \\beta_4*expt2 + \\beta_5*expt2*cov1$\n",
        "\n",
        "Note that currently, we only interact experimental treatments with covariates. \n",
        "\n",
        "The code written allows covariates to take on any (real) value, but experimental treatments are restricted to binary."
      ]
    },
    {
      "metadata": {
        "id": "CZunhoUEMJ0Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Experiment:\n",
        "  \"\"\"\n",
        "  A class that contains details of each experiment that is run.\n",
        "  \n",
        "  Parameters\n",
        "  ==========\n",
        "  \n",
        "  Covariates: number of covariates (int)\n",
        "  Experimental Variables: number of experimental variables (int)\n",
        "  Regression Model: LinearBayes object  \n",
        "  \n",
        "  This class uses the convention that in the dataset, covariates always appear to the LEFT of experimental variables.\n",
        "  \"\"\"\n",
        "  def __init__(self, covariates, exptvar, regressionmodel, datasource, coeffs):\n",
        "    self.covariates = covariates\n",
        "    self.exptvar = exptvar\n",
        "    self.regressionmodel = regressionmodel\n",
        "    self.data = datasource #np.loadtxt(datasource, delimiter = \",\", skiprows = 1)\n",
        "    self.numobs = len(self.data)\n",
        "    self.coeffs = coeffs\n",
        "      \n",
        "    \n",
        "  #def calculate_expected_value_in_each_treatment(self, observation, experiment):\n",
        "  def calculate_which_treatments_to_include(self, observation):\n",
        "    \"\"\"\n",
        "    Use the convention in the dataset:\n",
        "    [constant, covar1, covar2, ..., covarM, constant*exptvar1, covar1*exptvar1, ..., covarM*exptvar1, constant*exptvar2, covar1*exptvar2, ..., constant*exptvar3, ...]\n",
        "    assume each treatment is binary and treatments are mutually exclusive.\n",
        "\n",
        "    Pseudo-code:\n",
        "    For each experimental variable, calculate the contribution to expected value of dep var. Determine whether or not it should be included \n",
        "    (threshold: sum of all terms including exptvar1 is above zero, justified under the assumption that treatments do not interact).\n",
        "    \"\"\"\n",
        "    #exptvar = experiment.exptvar\n",
        "    #covariates = experiment.covariates \n",
        "    #numinteractions = exptvar*covariates      \n",
        "\n",
        "    coefficients = self.regressionmodel.thompson_sampling()\n",
        "    observationplusconstant = np.append(np.array([1]), observation)\n",
        "    treatments_to_use = []\n",
        "    for i in range(self.exptvar):\n",
        "      expectedeffect = 0\n",
        "      for j in range(self.covariates + 1):\n",
        "        # NOTE: add 1 to covariates because need constant\n",
        "        # Note we omit covariates as they are fixed.\n",
        "\n",
        "        expectedeffect += coefficients[(i + 1)*(self.covariates + 1) + j]*observationplusconstant[j]\n",
        "        # How this works in the case of 2 covar and 2 expt var: \n",
        "        # [constant cov1 cov2 expt1 expt1*cov1 expt1*cov2 expt2 expt2*cov1 expt2*cov2 expt3 expt3*cov1 expt3*cov2]\n",
        "        # 3 4 5, ... , 6, 7, 8, ... 9, 10, 11\n",
        "\n",
        "      if expectedeffect > (10 ** -5): # allow for floating point error\n",
        "        treatments_to_use += [i]\n",
        "\n",
        "    return treatments_to_use\n",
        "\n",
        "  def observe_reward(self, observationi, chosentreatments):\n",
        "    \"\"\"\n",
        "    Calculates reward based on observed characteristics and chosen treatments.\n",
        "    Real reward function has been specified by user before conducting simulations\n",
        "    \"\"\"\n",
        "    numcoeffs = (1 + len(observationi))*(1 + self.exptvar) # assuming constant is not included in observationi, else change to len(observationi)    \n",
        "    chosentreatments = [i + 1 for i in chosentreatments]\n",
        "    chosentreatments = [0] + chosentreatments # include intercept in chosen treatments; makes sure that initial values are not set to zero\n",
        "    observationi = np.append([1], observationi) # adds constant\n",
        "    values = np.array([observationi[j] if i in chosentreatments else 0 for i in range(self.exptvar + 1) for j in range(self.covariates + 1) ]) # assumes constant is included in observationi\n",
        "    # [constant cov1 cov2 expt1 expt1*cov1 expt1*cov2 expt2 expt2*cov1 expt2*cov2 expt3 expt3*cov1 expt3*cov2]\n",
        "    reward = np.dot(self.coeffs, values) + np.random.normal(scale = 3.0)\n",
        "    #print(observationi, chosentreatments, values, reward)\n",
        "    return reward, values\n",
        "  \n",
        "  def run_experiment(self, numpulls):\n",
        "    \"\"\"\n",
        "    Loads dataset\n",
        "    \n",
        "    For each observation:\n",
        "      Load observation (participant characteristics)\n",
        "      Thompson Sampling\n",
        "      calculate_which_treatments_to_include\n",
        "      Give treatments, observe reward\n",
        "      update prior      \n",
        "    \"\"\"\n",
        "    treatmentsgiven = np.zeros((self.exptvar,self.numobs))\n",
        "    # Expand data matrix to allow for interactions\n",
        "    \n",
        "    for i in range(numpulls):\n",
        "      observationi = self.data[i] # observationi only has covariates, i.e. no constants, no interactions between exptvar and covar\n",
        "      chosentreatments = self.calculate_which_treatments_to_include(observationi) # the line which calls Thompson Sampling implicitly assumes that model has covariates and a constant. INITIALIZE BAYESLINEAR OBJECT ACCORDINGLY\n",
        "      reward, values = self.observe_reward(observationi, chosentreatments) # seems ok, observationi assumed NOT to include covariates or interactions. \"values\" includes constant and all covariates-exptvar interactions\n",
        "      self.regressionmodel.set_posterior(values, reward) \n",
        "      self.regressionmodel.replace_prior()\n",
        "      #print(self.regressionmodel.v_mN[2:6])\n",
        "      #print(observationi, chosentreatments)\n",
        "      for j in chosentreatments:\n",
        "        # record treatments\n",
        "        treatmentsgiven[j,i] = 1\n",
        "        \n",
        "    return treatmentsgiven\n",
        "      \n",
        "      \n",
        "  \n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-E-2q4zYqog",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test cases\n",
        "\n",
        "# case 1\n",
        "\n",
        "Let the regression equation be given by\n",
        "\n",
        "$y = 0 + 0*cov1 + 2*expt1 - 4*expt1*cov1$\n",
        "\n",
        "One can imagine that $cov1$ is gender e.g. $cov1 == 1$ means male user, while $cov1 == 0$ indicates female user.\n",
        "\n",
        "And $expt1 == 1$ indicates the user is shown a male picture ($expt1 == 0$ indicates a female picture).\n",
        "\n",
        "From the regression equation, one can see that the optimal policy is to show males pictures of females, and vice-versa.\n",
        "\n",
        "\n",
        "# case 2\n",
        "\n",
        "$y = 0 + 0*cov1 + 5*expt1 -10*expt1*cov1 -5*expt2 + 10*expt2*cov1$\n",
        "\n",
        "This is similar to case 1, but there are two experimental treatments instead of 1.\n",
        "\n",
        "Optimal policy:\n",
        "\n",
        "if cov1 == 0: expt1 = 1 and expt2 = 0\n",
        "\n",
        "if cov1 == 1: expt1 = 0 and expt2 = 1\n",
        "\n",
        "# case 3\n",
        "\n",
        "$y = 4 + 3*cov1 - 2*cov2 + 20*expt1 -14*expt1*cov1 -14*expt1*cov2$\n",
        "\n",
        "In this case, there are two covariates and one experimental treatment.\n",
        "\n",
        "Optimal Policy is for expt1 to be 0 only when both cov1 and cov2 are zero, otherwise expt1 should be 1\n",
        "\n",
        "# case 4\n",
        "$y = 4 + 3*cov1 -2*cov2 -8*expt1 +12*expt1*cov1 + 11*expt1*cov2 -9*expt2 + 6*expt2*cov1 + 7*expt2*cov2$\n",
        "\n",
        "There are two covariates and two experimental treatments in this case.\n",
        "\n",
        "Optimal policy:\n",
        "expt1: should = 1 when cov1 OR cov2 = 1\n",
        "expt2: should = 1 when cov1 AND cov2 = 1\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Hy7j9J62194-",
        "colab_type": "code",
        "outputId": "8856d9fb-32dc-4039-d9f5-d99d354f66c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def printchosenaction(startobs, endobs):\n",
        "  category = datasource[startobs - 1:endobs]\n",
        "  chosenaction = treatmentschosen[:, startobs - 1:endobs]\n",
        "  df = pd.DataFrame(\n",
        "      {\n",
        "          \"obs no.\": [i for i in range(startobs, endobs + 1)],\n",
        "      }\n",
        "  \n",
        "  )\n",
        "  for i in range(1, numcovar + 1):\n",
        "    df[\"cov\" + str(i)] = [j[i-1] for j in category]\n",
        "    \n",
        "  for i in range(1, numexptvar + 1):\n",
        "    df[\"expt\" + str(i)] = [int(j) for j in chosenaction[i-1]]\n",
        "  print(df[[\"obs no.\"] + [\"cov\" + str(i) for i in range(1, numcovar + 1)] + [\"expt\" + str(i) for i in range(1, numexptvar + 1)]])\n",
        "  \n",
        "  \n",
        "# case 1\n",
        "# [constant cov1 expt1 expt1*cov1]\n",
        "# if cov1 == 0: !expt1\n",
        "# if cov1 == 1: expt1\n",
        "numcovar = 1\n",
        "numexptvar = 1\n",
        "numregcoef = (numcovar + 1)*(numexptvar + 1) # 2*2 = 4\n",
        "numobs = 500\n",
        "coefs = [0, 0, 2, -4]\n",
        "\n",
        "linbayes = LinearBayes(a_m0 = np.zeros(numregcoef), m_S0 = 100*np.eye(numregcoef), beta = 0.1)\n",
        "datasource = np.array([[np.random.randint(2)] for _ in range(numobs)])\n",
        "expt = Experiment(numcovar, numexptvar, linbayes, datasource, coefs)\n",
        "treatmentschosen = expt.run_experiment(numobs)\n",
        "\n",
        "print(\"Case 1: \\n\") \n",
        "print(\"expt1's value indicates which experimental treatment that the contextual multi-armed bandit assigned. \\n\") \n",
        "\n",
        "print(\"Initially, the bandit algorithm makes mistakes when assigning users to treatments. See below table for the first ten users. \\n\")\n",
        "\n",
        "print(\"Recall that cov1 == 1 could denote male users, cov1 == 0 indicates female users. expt1 == 1 denotes male photos while expt1 == 0 indicates female photos. \\n\")\n",
        "\n",
        "print(\"Notice the system makes mistakes: Some users see photos of the same gender, even though the optimal policy is to assign photos of the opposite gender. \\n\")\n",
        "\n",
        "\n",
        "printchosenaction(1, 10)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"The below table shows the treatments given to users 491 to 500. \\n\")\n",
        "\n",
        "print(\"Observe that the system has learnt the optimal personalized policy: male users are shown female photos, and vice-versa. \\n\")\n",
        "\n",
        "printchosenaction(491, 500)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Case 1: \n",
            "\n",
            "expt1's value indicates which experimental treatment that the contextual multi-armed bandit assigned. \n",
            "\n",
            "Initially, the bandit algorithm makes mistakes when assigning users to treatments. See below table for the first ten users. \n",
            "\n",
            "Recall that cov1 == 1 could denote male users, cov1 == 0 indicates female users. expt1 == 1 denotes male photos while expt1 == 0 indicates female photos. \n",
            "\n",
            "Notice the system makes mistakes: Some users see photos of the same gender, even though the optimal policy is to assign photos of the opposite gender. \n",
            "\n",
            "   obs no.  cov1  expt1\n",
            "0        1     0      1\n",
            "1        2     1      1\n",
            "2        3     1      1\n",
            "3        4     0      1\n",
            "4        5     1      0\n",
            "5        6     1      0\n",
            "6        7     0      1\n",
            "7        8     0      0\n",
            "8        9     0      1\n",
            "9       10     1      0\n",
            "\n",
            "\n",
            "The below table shows the treatments given to users 491 to 500. \n",
            "\n",
            "Observe that the system has learnt the optimal personalized policy: male users are shown female photos, and vice-versa. \n",
            "\n",
            "   obs no.  cov1  expt1\n",
            "0      491     1      0\n",
            "1      492     1      0\n",
            "2      493     0      1\n",
            "3      494     0      1\n",
            "4      495     1      0\n",
            "5      496     0      1\n",
            "6      497     0      1\n",
            "7      498     0      1\n",
            "8      499     1      0\n",
            "9      500     1      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5DX2oFmWYUkH",
        "colab_type": "code",
        "outputId": "69919010-2795-4fb8-dd0a-4e81357c21b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "# case 2\n",
        "# [constant cov1 expt1 expt1*cov1 expt2 expt2*cov1]\n",
        "# if cov1 == 0: expt1 and !expt2\n",
        "# if cov1 == 1: !expt1 and ~expt2\n",
        "numcovar = 1\n",
        "numexptvar = 2\n",
        "numregcoef = (numcovar + 1)*(numexptvar + 1) # 2*3 = 6\n",
        "numobs = 500\n",
        "coefs = [0, 0, 5, -10, -5, 10]\n",
        "\n",
        "linbayes = LinearBayes(a_m0 = np.zeros(numregcoef), m_S0 = 100*np.eye(numregcoef), beta = 0.1)\n",
        "datasource = np.array([[np.random.randint(2)] for _ in range(numobs)])\n",
        "expt = Experiment(numcovar, numexptvar, linbayes, datasource, coefs)\n",
        "treatmentschosen = expt.run_experiment(numobs)\n",
        "\n",
        "print(\"Case 2: \\n\") \n",
        "\n",
        "print(\"Again, the system makes mistakes initially but learns the optimal personalized policy as users make decisions. \\n\")\n",
        "printchosenaction(1, 10)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "printchosenaction(491, 500)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Case 2: \n",
            "\n",
            "Again, the system makes mistakes initially but learns the optimal personalized policy as users make decisions. \n",
            "\n",
            "   obs no.  cov1  expt1  expt2\n",
            "0        1     0      1      0\n",
            "1        2     0      1      1\n",
            "2        3     0      1      1\n",
            "3        4     0      1      0\n",
            "4        5     0      1      0\n",
            "5        6     1      0      1\n",
            "6        7     1      0      0\n",
            "7        8     1      0      1\n",
            "8        9     0      0      0\n",
            "9       10     1      1      0\n",
            "\n",
            "\n",
            "   obs no.  cov1  expt1  expt2\n",
            "0      491     1      0      1\n",
            "1      492     1      0      1\n",
            "2      493     1      0      1\n",
            "3      494     0      1      0\n",
            "4      495     1      0      1\n",
            "5      496     0      1      0\n",
            "6      497     0      1      0\n",
            "7      498     1      1      1\n",
            "8      499     0      1      0\n",
            "9      500     1      0      1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2PTjaYzAFMux",
        "colab_type": "code",
        "outputId": "87e5856c-ad6a-4b68-b8c0-6d7ef388c0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# case 3\n",
        "# [constant cov1 cov2 expt1 expt1*cov1 expt1*cov2]\n",
        "# expt1 should = 0 iff cov1 and cov2 are 1\n",
        "numcovar = 2\n",
        "numexptvar = 1\n",
        "numregcoef = (numcovar + 1)*(numexptvar + 1) # 2*3 = 6\n",
        "numobs = 500\n",
        "coefs = [4, 3, -2, 20, -14, -14]\n",
        "\n",
        "linbayes = LinearBayes(a_m0 = np.zeros(numregcoef), m_S0 = 100*np.eye(numregcoef), beta = 0.1)\n",
        "datasource = np.array([[np.random.randint(2), np.random.randint(2)] for _ in range(numobs)])\n",
        "expt = Experiment(numcovar, numexptvar, linbayes, datasource, coefs)\n",
        "treatmentschosen = expt.run_experiment(numobs)\n",
        "\n",
        "print(\"Case 3: \\n\") \n",
        "printchosenaction(1, 10)\n",
        "printchosenaction(491, 500)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Case 3: \n",
            "\n",
            "   obs no.  cov1  cov2  expt1\n",
            "0        1     0     1      1\n",
            "1        2     1     1      0\n",
            "2        3     0     0      1\n",
            "3        4     1     1      1\n",
            "4        5     0     1      0\n",
            "5        6     1     0      0\n",
            "6        7     0     0      1\n",
            "7        8     0     0      1\n",
            "8        9     0     0      1\n",
            "9       10     0     0      1\n",
            "   obs no.  cov1  cov2  expt1\n",
            "0      491     1     1      0\n",
            "1      492     0     1      1\n",
            "2      493     1     1      0\n",
            "3      494     1     1      0\n",
            "4      495     0     0      1\n",
            "5      496     0     0      1\n",
            "6      497     0     0      1\n",
            "7      498     1     0      1\n",
            "8      499     0     0      1\n",
            "9      500     1     1      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K-bAvXsFHhYz",
        "colab_type": "code",
        "outputId": "06b9338e-59ab-4503-aa8e-74d0bc8fadae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# case 4\n",
        "# [constant cov1 cov2 expt1 expt1*cov1 expt1*cov2 expt2 expt2*cov1 expt2*cov2]\n",
        "# expt1: OR\n",
        "# expt2: AND\n",
        "\n",
        "numcovar = 2\n",
        "numexptvar = 2\n",
        "numregcoef = (numcovar + 1)*(numexptvar + 1) # 3*3 = 9\n",
        "numobs = 500\n",
        "coefs = [4, 3, -2, -8, 12, 11, -9, 6, 7]\n",
        "\n",
        "linbayes = LinearBayes(a_m0 = np.zeros(numregcoef), m_S0 = 100*np.eye(numregcoef), beta = 0.1)\n",
        "datasource = np.array([[np.random.randint(2), np.random.randint(2)] for _ in range(numobs)])\n",
        "expt = Experiment(numcovar, numexptvar, linbayes, datasource, coefs)\n",
        "treatmentschosen = expt.run_experiment(numobs)\n",
        "\n",
        "print(\"Case 4: \\n\") \n",
        "printchosenaction(1, 10)\n",
        "printchosenaction(491, 500)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Case 4: \n",
            "\n",
            "   obs no.  cov1  cov2  expt1  expt2\n",
            "0        1     0     0      0      1\n",
            "1        2     0     1      0      1\n",
            "2        3     1     1      0      0\n",
            "3        4     1     0      1      1\n",
            "4        5     0     1      1      0\n",
            "5        6     1     1      0      0\n",
            "6        7     0     1      1      1\n",
            "7        8     1     0      1      0\n",
            "8        9     1     0      0      0\n",
            "9       10     0     0      1      1\n",
            "   obs no.  cov1  cov2  expt1  expt2\n",
            "0      491     0     1      1      0\n",
            "1      492     1     0      1      0\n",
            "2      493     0     1      1      0\n",
            "3      494     0     1      1      0\n",
            "4      495     1     1      1      1\n",
            "5      496     0     0      0      0\n",
            "6      497     0     1      1      0\n",
            "7      498     1     0      1      0\n",
            "8      499     1     1      1      1\n",
            "9      500     1     0      1      0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}